{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_Breast_Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjLmq3Sg+976Rf013gbOFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naokityokoyama/Deep_Learing/blob/main/Deep_learning_Breast_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQgvTC550v-z"
      },
      "source": [
        "## Breast_Cancer - UCI\r\n",
        "\r\n",
        "Problema de Classificação Binario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I5NDjTEX_RTA",
        "outputId": "c904bef5-0a25-41f5-a426-7e4fc53f777e"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xwqkIcC0XcT"
      },
      "source": [
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import keras\r\n",
        "from keras.models import Sequential #classe mais usada na rede reural pois ele é modelo sequencial camada de entrada, camada oculta, camada saida\r\n",
        "from keras.layers import Dense # Dense é a ligação de todos os neoroneos \r\n",
        "from keras.layers import Flatten\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tC9Umey1zY7"
      },
      "source": [
        "entradas = pd.read_csv('/content/1.1 entradas_breast.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tpHOeGP2Y1n"
      },
      "source": [
        "classe = pd.read_csv('/content/1.2 saidas_breast.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61TBjnLS27Hl"
      },
      "source": [
        "X = entradas\r\n",
        "y = classe"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEDQFecO3Ga_"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISvuJu1f41Ad"
      },
      "source": [
        "Nesse modelo temos 30 features, entao seria 30 \r\n",
        "                    \r\n",
        "2 classe, sendo 2 saidas \r\n",
        "                    \r\n",
        "A formula para saber quantos neuroneios na 1 camada oculta é (30 + 1) / 2 (ponto de partida)   30 featuras + 1 que é a saida de resposta (queremos apenas 1 resposta ou 0 ou 1) \r\n",
        "\r\n",
        "Dense(units= quantidade de neuroneos na camada oculta, actiarion = funsão ativaçãom, kerner_initializar= pesos, input_dim = (quantidade de entradas no caso 30 pois tem 30 features) -> aqui a camada de entrada e a primeira oculta ficam juntas\r\n",
        "\r\n",
        "Camada de saida - unit=1 pois quer apenas 1 resposta imprime 0 ou imprime 1, sigmoide foi a ativacao escolhida pois ela se trata de binaria\r\n",
        "\r\n",
        "\r\n",
        "compile (é a compitação , optimaze seria o ajuste dos pesos e o adam seria uma da funcao da descida do gradiente , loss-> perda "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V7U8w0L4Qii",
        "outputId": "1aa209d2-489f-436e-f08c-8d6f6001c888"
      },
      "source": [
        "classificador = Sequential()\r\n",
        "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) # deu 15,5 arredonda para 16\r\n",
        "classificador.add(Dense(units=1, activation='sigmoid'))\r\n",
        "\r\n",
        "classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['binary_accuracy'])\r\n",
        "\r\n",
        "classificador.fit(X_train, y_train, batch_size=10, epochs=100) #barch_size é a ideia do gradient em vez de fazer 1 em 1 aqui seria 10 em 10"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 1ms/step - loss: 58.0930 - binary_accuracy: 0.4631\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 2.0808 - binary_accuracy: 0.7060\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 1.0616 - binary_accuracy: 0.7276\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8111 - binary_accuracy: 0.7961\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4582 - binary_accuracy: 0.8409\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4654 - binary_accuracy: 0.8842\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3479 - binary_accuracy: 0.8839\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3860 - binary_accuracy: 0.8601\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2921 - binary_accuracy: 0.8941\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2907 - binary_accuracy: 0.9042\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8118 - binary_accuracy: 0.8230\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3028 - binary_accuracy: 0.9159\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2938 - binary_accuracy: 0.8953\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3034 - binary_accuracy: 0.9001\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3124 - binary_accuracy: 0.8999\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3013 - binary_accuracy: 0.8807\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2099 - binary_accuracy: 0.9220\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7063 - binary_accuracy: 0.8080\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3919 - binary_accuracy: 0.8699\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3179 - binary_accuracy: 0.8900\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3082 - binary_accuracy: 0.9006\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4173 - binary_accuracy: 0.8406\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3727 - binary_accuracy: 0.8966\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1424 - binary_accuracy: 0.9436\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_accuracy: 0.8895\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3166 - binary_accuracy: 0.8881\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2971 - binary_accuracy: 0.9095\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3227 - binary_accuracy: 0.9078\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1865 - binary_accuracy: 0.9324\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3052 - binary_accuracy: 0.9076\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8375 - binary_accuracy: 0.8382\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4619 - binary_accuracy: 0.8647\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2953 - binary_accuracy: 0.9248\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7350 - binary_accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4089 - binary_accuracy: 0.8814\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3156 - binary_accuracy: 0.9325\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2340 - binary_accuracy: 0.9275\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3128 - binary_accuracy: 0.9006\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2935 - binary_accuracy: 0.9123\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4755 - binary_accuracy: 0.8723\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5613 - binary_accuracy: 0.8802\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1827 - binary_accuracy: 0.9381\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1839 - binary_accuracy: 0.9490\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3147 - binary_accuracy: 0.9252\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2752 - binary_accuracy: 0.9131\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1814 - binary_accuracy: 0.9394\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4510 - binary_accuracy: 0.8915\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3594 - binary_accuracy: 0.8964\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2861 - binary_accuracy: 0.9321\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2301 - binary_accuracy: 0.9369\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5860 - binary_accuracy: 0.8482\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3185 - binary_accuracy: 0.9041\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2283 - binary_accuracy: 0.9240\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.9853 - binary_accuracy: 0.8623\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3071 - binary_accuracy: 0.9241\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4875 - binary_accuracy: 0.8910\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3927 - binary_accuracy: 0.8963\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3225 - binary_accuracy: 0.9287\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2266 - binary_accuracy: 0.9352\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.9027\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3831 - binary_accuracy: 0.9007\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8616 - binary_accuracy: 0.8347\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3420 - binary_accuracy: 0.9126\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3510 - binary_accuracy: 0.9199\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2955 - binary_accuracy: 0.9113\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2462 - binary_accuracy: 0.9218\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2399 - binary_accuracy: 0.9310\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3344 - binary_accuracy: 0.9058\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5799 - binary_accuracy: 0.8976\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1960 - binary_accuracy: 0.9230\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2807 - binary_accuracy: 0.9015\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3443 - binary_accuracy: 0.9232\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5036 - binary_accuracy: 0.8725\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5604 - binary_accuracy: 0.8527\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3811 - binary_accuracy: 0.8955\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2641 - binary_accuracy: 0.9337\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1205 - binary_accuracy: 0.9629\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 0.9396\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5828 - binary_accuracy: 0.8992\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6912 - binary_accuracy: 0.8687\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2904 - binary_accuracy: 0.9390\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2830 - binary_accuracy: 0.9029\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2671 - binary_accuracy: 0.9069\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4168 - binary_accuracy: 0.8988\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3163 - binary_accuracy: 0.9302\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3209 - binary_accuracy: 0.9347\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2174 - binary_accuracy: 0.9487\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2266 - binary_accuracy: 0.9259\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2144 - binary_accuracy: 0.9302\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2652 - binary_accuracy: 0.9421\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2740 - binary_accuracy: 0.9382\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2180 - binary_accuracy: 0.9280\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1190 - binary_accuracy: 0.9546\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1648 - binary_accuracy: 0.9511\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2804 - binary_accuracy: 0.9306\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3233 - binary_accuracy: 0.9195\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1624 - binary_accuracy: 0.9319\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2900 - binary_accuracy: 0.9008\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2151 - binary_accuracy: 0.9335\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2975 - binary_accuracy: 0.9108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe71e327fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg3oPcBZDZVn"
      },
      "source": [
        "y_pred = classificador.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UfreFSTEpXG"
      },
      "source": [
        "y_predict = (y_pred > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH8_hhPIEgZ5",
        "outputId": "8af34683-9619-428e-e583-b2e8a6d04251"
      },
      "source": [
        "accuracy_score(y_test, y_pred.round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8181818181818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p50sSQIG72L",
        "outputId": "4dfc45fb-1bfc-4ea1-cbfc-7a8a8a2d15f8"
      },
      "source": [
        "accuracy_score(y_test, y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8181818181818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bw2L6mwHEXB"
      },
      "source": [
        "matriz = confusion_matrix(y_test, y_predict)\r\n",
        "matriz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGS7WgrmHTlM",
        "outputId": "76c6d33a-ae4c-4748-cbe1-22be4500ceb8"
      },
      "source": [
        "#resultado atraves do keras \r\n",
        "resultado = classificador.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0519 - binary_accuracy: 0.8182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpxk79ufK9HH"
      },
      "source": [
        "Adam( **lr** learing rating -> taxa de aprentizado que foi passado, e o **decay** acelera no inicio e vai dimunuindo\r\n",
        "**clip** value é uma especie de clip mesmo entre -0,5 e 0,5 ele vai congelar quando achar um valor melhor (pois se nao usar ele pode ficar uma especia de ping, pong com o clip ele prende no ponto e desce prende e desce assim...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY9IEoSUJjxv",
        "outputId": "767511b8-878d-4bb5-a48b-19a5df8d36c1"
      },
      "source": [
        "#mais uma camada e ajustando adam\r\n",
        "classificador = Sequential()\r\n",
        "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) \r\n",
        "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \r\n",
        "classificador.add(Dense(units=1, activation='sigmoid'))\r\n",
        "#configurando o adam\r\n",
        "optimizador = keras.optimizers.Adam(lr=0.001, decay=0.0001, clipvalue=0.5)\r\n",
        "\r\n",
        "classificador.compile(optimizer=optimizador , loss='binary_crossentropy', metrics= ['binary_accuracy'])\r\n",
        "\r\n",
        "classificador.fit(X_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 1ms/step - loss: 1.1586 - binary_accuracy: 0.5799\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5378 - binary_accuracy: 0.7502\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4358 - binary_accuracy: 0.7933\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5567 - binary_accuracy: 0.7735\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4876 - binary_accuracy: 0.7671\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4588 - binary_accuracy: 0.7947\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5055 - binary_accuracy: 0.7911\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3976 - binary_accuracy: 0.8217\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4294 - binary_accuracy: 0.8426\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4432 - binary_accuracy: 0.8401\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3790 - binary_accuracy: 0.8638\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4641 - binary_accuracy: 0.8401\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4008 - binary_accuracy: 0.8248\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 1.0451 - binary_accuracy: 0.7667\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.0373 - binary_accuracy: 0.8329\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3588 - binary_accuracy: 0.8805\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4154 - binary_accuracy: 0.8677\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4330 - binary_accuracy: 0.8764\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6809 - binary_accuracy: 0.7766\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5004 - binary_accuracy: 0.8791\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8932\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5330 - binary_accuracy: 0.8739\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6375 - binary_accuracy: 0.8211\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8805\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3891 - binary_accuracy: 0.8707\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5904 - binary_accuracy: 0.8227\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4888 - binary_accuracy: 0.8808\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5479 - binary_accuracy: 0.8471\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5935 - binary_accuracy: 0.8202\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5141 - binary_accuracy: 0.8337\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6585 - binary_accuracy: 0.8217\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4997 - binary_accuracy: 0.8359\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6101 - binary_accuracy: 0.8331\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4335 - binary_accuracy: 0.8548\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5764 - binary_accuracy: 0.8191\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5020 - binary_accuracy: 0.8701\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4614 - binary_accuracy: 0.8633\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3927 - binary_accuracy: 0.8741\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4655 - binary_accuracy: 0.8391\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3745 - binary_accuracy: 0.8980\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7010 - binary_accuracy: 0.8296\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4286 - binary_accuracy: 0.8567\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4470 - binary_accuracy: 0.8689\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3833 - binary_accuracy: 0.8675\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4490 - binary_accuracy: 0.8785\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3988 - binary_accuracy: 0.8786\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4387 - binary_accuracy: 0.8676\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4381 - binary_accuracy: 0.9002\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4422 - binary_accuracy: 0.8921\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5317 - binary_accuracy: 0.8633\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5601 - binary_accuracy: 0.8739\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6806 - binary_accuracy: 0.8155\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3826 - binary_accuracy: 0.9066\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4452 - binary_accuracy: 0.8688\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5271 - binary_accuracy: 0.8263\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4648 - binary_accuracy: 0.8721\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4778 - binary_accuracy: 0.8535\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4898 - binary_accuracy: 0.8390\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7064 - binary_accuracy: 0.8674\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3970 - binary_accuracy: 0.8569\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4877 - binary_accuracy: 0.8913\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3731 - binary_accuracy: 0.8939\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4848 - binary_accuracy: 0.8665\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4793 - binary_accuracy: 0.8646\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4257 - binary_accuracy: 0.8639\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4061 - binary_accuracy: 0.8690\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4422 - binary_accuracy: 0.8691\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4217 - binary_accuracy: 0.8662\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4885 - binary_accuracy: 0.8630\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3286 - binary_accuracy: 0.8930\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4654 - binary_accuracy: 0.8611\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5487 - binary_accuracy: 0.8430\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4016 - binary_accuracy: 0.8830\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5047 - binary_accuracy: 0.8637\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5077 - binary_accuracy: 0.8642\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7371 - binary_accuracy: 0.8611\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7047 - binary_accuracy: 0.8335\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4635 - binary_accuracy: 0.8696\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5888 - binary_accuracy: 0.8374\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5777 - binary_accuracy: 0.8154\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6963 - binary_accuracy: 0.8463\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7040 - binary_accuracy: 0.8420\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.9852 - binary_accuracy: 0.8512\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3757 - binary_accuracy: 0.8961\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8227 - binary_accuracy: 0.7705\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6075 - binary_accuracy: 0.8643\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4434 - binary_accuracy: 0.8857\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5015 - binary_accuracy: 0.8515\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4346 - binary_accuracy: 0.8999\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.8363\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6594 - binary_accuracy: 0.8607\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7412 - binary_accuracy: 0.8621\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7055 - binary_accuracy: 0.7919\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5585 - binary_accuracy: 0.8795\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4287 - binary_accuracy: 0.8940\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5182 - binary_accuracy: 0.8567\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4880 - binary_accuracy: 0.8386\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4626 - binary_accuracy: 0.8806\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6587 - binary_accuracy: 0.8389\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5131 - binary_accuracy: 0.8720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f391eaf9898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rrISr2_JvXY",
        "outputId": "1c5e43b7-c6c1-4963-8701-9b73b828e202"
      },
      "source": [
        "#resultado atraves do keras \r\n",
        "resultado = classificador.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2976 - binary_accuracy: 0.7063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4udmGmpNbRG"
      },
      "source": [
        "pesos0 = classificador.layers[0].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSDurUy7Nh8-"
      },
      "source": [
        "print (pesos0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glaePXwoObiL",
        "outputId": "54bc57a7-3a56-480e-a09b-705620691d22"
      },
      "source": [
        "print (len(pesos0)) # aparece 2 pois um é a camada oculta e o outro é a Bias (visto em aula teorica para desabilitar o bias é no Dense)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSFB5tYcNwHO"
      },
      "source": [
        "pesos1 = classificador.layers[1].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOCi3GzOOQpj",
        "outputId": "f67a64d8-90aa-4d40-d913-da81cc09249d"
      },
      "source": [
        "pesos1[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23240866, -0.01660141,  0.12569751,  0.1951989 , -0.24249315,\n",
              "        0.        , -0.1567598 , -0.07110898, -0.01493478,  0.17350763,\n",
              "        0.23035978, -0.05342744,  0.16857906, -0.25377014,  0.16267404,\n",
              "       -0.12793157], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    }
  ]
}